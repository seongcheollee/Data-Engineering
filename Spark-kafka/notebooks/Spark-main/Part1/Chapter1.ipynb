{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4849b4da-82df-481c-b1d9-05b43188daad",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 아파치 스파크란"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "3f2162bb-171c-4de7-b9a3-4e7507d13e68",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "- 통합 컴퓨팅 엔진이며, 클러스터 환경에서 데이터를 병렬로 처리하는 라이브러리 집합\n",
    "- 파이썬, 자바, 스칼라, R 지원\n",
    "- SQL뿐만 아니라 스트리밍, 머신러닝까지 넓은 범위의 라이브러리 제공\n",
    "- 단일 노트북 환경에서부터 수천 대의 서버로 구성된 클러스터까지 다양한 환경에서 실행 가능\n",
    "\n",
    "<img src=\"https://uploads-ssl.webflow.com/5e724862760345325327026c/5fa7ecda6639f6566345729b_Apache%20Spark%20Ecosystem%20PNG.png\" width=50%; height=50;/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "10a4e6c4-402d-4b63-82a8-8e30a81f0b25",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 아파치 스파크의 철학\n",
    "### \"빅데이터를 위한 통합 컴퓨팅 엔진과 라이브러리 집합\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "6f846a81-3581-42dc-9bac-e49c3e368547",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 통합\n",
    "- 스파크의 핵심 목표: '빅데이터 애플리케이션 개발에 필요한 <strong>통합 플랫폼</strong>을 제공하자'\n",
    "\n",
    "- 통합의 의미? \n",
    "  - 간단한 데이터 읽기에서부터 SQL처리, 머신러닝, 스트림 처리 등\n",
    "  - 다양한 데이터 분석 작업을 <strong>같은 연산 엔진과 일관성 있는 API로 수행</strong>할 수 있도록 설계\n",
    "  \n",
    "- 스파크는 일관성 있는 <strong>조합형 API</strong>를 제공하므로 <strong>작은 코드 조각이나 기존 라이브러리를 사용해</strong> 애플리케이션을 만들 수 있다.\n",
    "\n",
    "- 스파크의 API는 사용자 애플리케이션에서 <strong>다른 라이브러리의 기능을 조합</strong>해 더 나은 성능을 발휘할 수 있도록 설계되었다.\n",
    "  - ex) SQL쿼리로 데이터를 읽고 ML라이브러리로 머신러닝 모델 평가<br>\n",
    "  -> 스파크 엔진은 이 <strong>두 단계를 하나로 병합하고 데이터를 한 번만 조회</strong>할 수 있게 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2bd34b3b-2807-40fc-b199-04c2ce73b277",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 컴퓨팅 엔진\n",
    "- 스파크는 통합이라는 관점을 중시하며 기능의 범위를 컴퓨팅 엔진으로 제한해옴\n",
    "\n",
    "- 따라서 저장소 시스템의 <strong>데이터를 연산하는 역할만<strong> 수행할 뿐, 영구 저장소 역할은 수행하지 않음\n",
    "- 그 대신, 다음과 같은 저장소 지원 \n",
    "  - Azure Storage\n",
    "  - Amazon S3\n",
    "  - 분산 파일 시스템인 Apache Hadoop\n",
    "  - 키/값 저장소인 Apache Cassandra\n",
    "  - 메시지 전달 서비스인 Apache Kafka\n",
    "  - etc.\n",
    "  \n",
    "- 스파크는 <strong>데이터 저장 위치에 상관없이 처리에 집중</strong>하도록 만들어짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "0da121f5-382b-497b-9f80-eaa64863a888",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 라이브러리\n",
    "- 다양한 외부 라이브러리 지원\n",
    "  - 오픈소스 커뮤니티에서 서드파티 패키지 형태로 제공\n",
    "  - https://spark-packages.org/\n",
    "  \n",
    "- 표준 라이브러리 지원\n",
    "  - 사실 스파크의 표준 라이브러리는 여러 오픈소스 프로젝트의 집합체\n",
    "  - <strong>스파크 SQL</strong>: SQL과 구조화된 데이터를 제공\n",
    "  - <strong>MLlib</strong>: 머신러닝 지원\n",
    "  - <strong>스파크 스트리밍&구조적 스트리밍</strong>: 스트림 처리 기능 제공\n",
    "  - <strong>GraphX</strong>: 그래프 분석 엔진 제공\n",
    "\n",
    "- 스파크 코어 엔진 자체는 최초 공개 후 큰 변화가 없었지만 라이브러리는 더 많은 기능을 제공하기 위해 꾸준히 변해옴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "308cdef1-816a-4f85-b664-3c806c78b001",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 스파크의 등장 배경\n",
    "\n",
    "- 데이터 분석에 <strong>새로운 처리 엔진과 프로그래밍 모델이 필요</strong>한 근본적인 이유는?\n",
    "  - 데이터 수집 비용은 극히 저렴해졌지만, <strong>데이터는 클러스터에서 처리해야 할 만큼 거대해짐</strong>\n",
    "    - 데이터 수집에 필요한 기술 비용은 계속해서 저렴해짐\n",
    "    - 정밀도는 개선됨\n",
    "    \n",
    "  - 게다가 지난 50년간 개발된 <strong>sw는 더는 자동으로 성능이 향상되지 않음</strong>\n",
    "    - 단일 프로세서 성능 향상의 한계\n",
    "  \n",
    "- 그래서 <strong>아파치 스파크</strong>가 탄생"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a271f49a-0ee8-4580-a7d2-c4bf72c50997",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 스파크의 역사\n",
    "\n",
    "- UC버클리 대학교에서 2009년 스파크 연구 프로젝트로 시작\n",
    "  - 당시엔 하둡 맵리듀스가 클러스터 환경용 병렬 프로그래밍 엔진 대표주자였음\n",
    "\n",
    "- 연구 결과로 명확해진 두 가지 사실\n",
    "  1. 클러스터 컴퓨팅이 엄청난 잠재력을 가짐\n",
    "  2. 맵리듀스 엔진을 사용하는 대규모 애플리케이션의 난이도와 효율성 문제\n",
    "    - ex) 전통적인 머신러닝 알고리즘은 데이터를 10~20회 가량 처리함<br>\n",
    "      -> 이를 맵리듀스로 처리하려면 매번 데이터를 처음부터 읽어야함\n",
    "\n",
    "- 위 사실을 기반으로, <strong>'여러 단계로 이루어진 애플리케이션을 간결하게 개발할 수 있는 함수형 프로그래밍 기반의 API'</strong> 개발\n",
    "  - 연산 단계 사이에서 <strong>메모리에 저장된 데이터를 효율적으로 공유</strong>할 수 있는 새로운 엔진 기반의 API 구현\n",
    "  \n",
    "- 1.0 이전의 스파크 초기 버전은 함수형 연산 관점에서 API를 정의\n",
    "- 1.0 부터는 구조화된 데이터를 기반으로 동작하는 신규 API인 스파크 SQL이 추가\n",
    "- 시간이 흘러 DataFrame, 머신러닝 파이프라인, 자동 최적화를 수행하는 구조적 스트리밍 등 더 강력한 구조체 기반의 신규 API 추가"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Chapter1",
   "notebookOrigID": 4377204471961401,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
